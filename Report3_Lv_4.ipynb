{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Report3_Lv.4.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MRyo-ie/DataMining_Report3_Lv4_NLP_Models/blob/GoogleColab-merge/Report3_Lv_4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ytKWwxITuiOK",
        "colab_type": "text"
      },
      "source": [
        "# Report3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jv_tdY_kpkwW",
        "colab_type": "text"
      },
      "source": [
        "## Level 4: 文書分類せよ。\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xQI8s3RxSO36",
        "colab_type": "code",
        "outputId": "d23b023e-548c-453d-805b-a1572807b9bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# 自分の Google Drive をマウント\n",
        "# https://qiita.com/uni-3/items/201aaa2708260cc790b8#drive内のディレクトリをマウントする220180920\n",
        "from google.colab import drive\n",
        "import os\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "#@markdown ### GitHubリポジトリをcloneして保存するパス （Google Drive上）\n",
        "REPOSITORY_ROOT_DIR = 'Colab Notebooks/learning/old_nlp_techs' #@param {type: \"string\"}"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QMga8fELbUHX",
        "colab_type": "text"
      },
      "source": [
        "### <<  実行手順  >>\n",
        "\n",
        "1.   このボタンを押す　→　　[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/googlecolab/colabtools/blob/master/notebooks/colab-github-demo.ipynb)\n",
        "1. ↖︎（左上）のどこかに、「ドライブに保存」があるので、それをクリックして、  \n",
        "  自分の Google Drive にこのファイルをコピーする。\n",
        "1. ↑ の変数を設定する。\n",
        "1. 実行。  \n",
        "  （↑で GoogleDrive をマウントするので、（英語の）指示に従って、  \n",
        "   「ログイン」→「パスコードをコピー」→「四角枠に貼り付けしてEnter」）\n",
        "1. 後は勝手に実行してくれるはず(笑)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "aZTAWBqnXR45"
      },
      "source": [
        "### 【準備】 データ\n",
        "今回は livedoor の記事データセットを使用。\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "906T09c6azyW",
        "colab": {}
      },
      "source": [
        "import configparser\n",
        "import glob\n",
        "import os, sys\n",
        "import pandas as pd\n",
        "import subprocess\n",
        "import tarfile\n",
        "from tqdm import tqdm\n",
        "from urllib.request import urlretrieve"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "cefTwUbsegWV",
        "outputId": "fd953c2c-b85a-4981-cda7-b4fcf5b6826c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "REPOSITORY_URL = ''\n",
        "DATA_DL_URL = \"https://www.rondhuit.com/download/ldcc-20140209.tar.gz\"\n",
        "GDRIVE_ROOT = '/content/gdrive/My Drive/'\n",
        "REPO_PATH = os.path.join(GDRIVE_ROOT, REPOSITORY_ROOT_DIR)\n",
        "\n",
        "# よく使うパス\n",
        "DATA_DIR = os.path.join(REPO_PATH, 'datas', 'articles_livedoor')\n",
        "TMP_DIR = os.path.join(DATA_DIR, 'tmp')\n",
        "FILE_PATH = os.path.join(DATA_DIR, 'tmp', DATA_DL_URL.split('/')[-1])\n",
        "\n",
        "print(\"\"\"\n",
        "------------------------\n",
        "<<<  パス一覧  >>>\n",
        "REPO_PATH = {}\n",
        "\n",
        "DATA_DL_URL = {}\n",
        "DATA_DIR = {}\n",
        "TMP_DIR = {}\n",
        "FILE_PATH = {}\n",
        "\"\"\".format(REPO_PATH, DATA_DL_URL, DATA_DIR, TMP_DIR, FILE_PATH))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "FILEURL = https://www.rondhuit.com/download/ldcc-20140209.tar.gz\n",
            "FILEPATH = /content/gdrive/My Drive/\n",
            "EXTRACTDIR = /content/gdrive/My Drive/Colab Notebooks/datasets/[NLP]「コーパス」/livedoor/ldcc-20140209.tar.gz\n",
            "\n",
            "REPOSITORY_ROOT_DIR = /content/gdrive/My Drive/Colab Notebooks/datasets/[NLP]「コーパス」/livedoor\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hGvxmrZk6NZ6",
        "colab_type": "text"
      },
      "source": [
        "#### 読み込み"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "aJ4AQJNQeaxT",
        "outputId": "9f30cf0b-2f77-4dca-9f24-aac849ab511b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# 本家データセット に更新があった場合\n",
        "is_renew_file = False\n",
        "\n",
        "%cd  \"$TMP_DIR/\"\n",
        "if not os.path.exists(FILE_PATH) or is_renew_file:\n",
        "    ! wget  \"$DATA_DL_URL\"\n",
        "\n",
        "if is_renew_file:\n",
        "    # 時間かかる。\n",
        "    !tar  -zxvf   'ldcc-20140209.tar.gz'\n",
        "    !ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/Colab Notebooks/datasets/[NLP]「コーパス」/livedoor\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LU0ddAwymB21",
        "colab": {}
      },
      "source": [
        "categories = [ \n",
        "    name for name \n",
        "    in os.listdir( os.path.join(TMP_DIR, \"text\") ) \n",
        "    if os.path.isdir( os.path.join(TMP_DIR, \"text\", name) ) ]\n",
        "\n",
        "categories = sorted(categories)\n",
        "categories"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "UY_enZFuWDYV"
      },
      "source": [
        "#### データの抽出・整備\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "VzwBKkN5X_k_"
      },
      "source": [
        "- ラベル（記事の種類）一覧"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9XROrL41mHON",
        "outputId": "8c06ff39-a3b8-4b4a-b2c2-645d85acc9a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "table = str.maketrans({\n",
        "    '\\n': '',\n",
        "    '\\t': '　',\n",
        "    '\\r': '',\n",
        "})\n",
        "\n",
        "def extract_txt(filename):\n",
        "    with open(filename) as text_file:\n",
        "        # 0: URL, 1: timestamp\n",
        "        text = text_file.readlines()[2:]\n",
        "        text = [sentence.strip() for sentence in text]\n",
        "        text = list(filter(lambda line: line != '', text))\n",
        "        return ''.join(text)\n",
        "\n",
        "%cd  \"$TMP_DIR/\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/Colab Notebooks/datasets/[NLP]「コーパス」/livedoor\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "uwWtI1oLmLoL",
        "outputId": "224c8442-8b2b-48bd-ea2d-58de2d235936",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "%cd  \"$TMP_DIR/\"\n",
        "all_text = []\n",
        "all_label = []\n",
        "\n",
        "# 割と時間かかる。\n",
        "for cat in tqdm(categories):\n",
        "    files = glob.glob(os.path.join(\"text\", cat, \"{}*.txt\".format(cat)))\n",
        "    files = sorted(files)\n",
        "    body = [ extract_txt(elem).translate(table) for elem in files ]\n",
        "    label = [cat] * len(body)\n",
        "    \n",
        "    all_text.extend(body)\n",
        "    all_label.extend(label)\n",
        "\n",
        "print(all_label)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  0%|          | 0/9 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/Colab Notebooks/datasets/[NLP]「コーパス」/livedoor\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 11%|█         | 1/9 [00:01<00:10,  1.26s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 22%|██▏       | 2/9 [00:02<00:08,  1.15s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 33%|███▎      | 3/9 [00:02<00:06,  1.05s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 44%|████▍     | 4/9 [01:15<01:52, 22.47s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-48-97d8fd405848>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mfiles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"text\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"{}*.txt\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mfiles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mbody\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m \u001b[0mextract_txt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranslate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtable\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0melem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfiles\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-48-97d8fd405848>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mfiles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"text\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"{}*.txt\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mfiles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mbody\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m \u001b[0mextract_txt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranslate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtable\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0melem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfiles\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-47-f3886bca5261>\u001b[0m in \u001b[0;36mextract_txt\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtext_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;31m# 0: URL, 1: timestamp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msentence\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mline\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/codecs.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, input, final)\u001b[0m\n\u001b[1;32m    316\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 318\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    319\u001b[0m         \u001b[0;31m# decode input (taking the buffer into account)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuffer\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "-2lrwW7OYHXC"
      },
      "source": [
        "- 特徴量とラベル"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "n7qEl5ZMmOYa",
        "colab": {}
      },
      "source": [
        "df = pd.DataFrame({'text' : all_text, 'label' : all_label})\n",
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kgGmT86omSi9",
        "colab": {}
      },
      "source": [
        "df = df.sample(frac=1, random_state=23).reset_index(drop=True)\n",
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Xdt92AsGYMqV"
      },
      "source": [
        "- データを csv に保存する。\n",
        "  (機械学習モデル用)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2ruzfKDRmWZ7",
        "colab": {}
      },
      "source": [
        "df[:len(df) // 5].to_csv( os.path.join(TMP_DIR, 'extracts', \"test.tsv\"), sep='\\t', index=False)\n",
        "df[len(df) // 5:len(df)*2 // 5].to_csv( os.path.join(TMP_DIR, 'extracts', \"dev.tsv\"), sep='\\t', index=False)\n",
        "df[len(df)*2 // 5:].to_csv( os.path.join(TMP_DIR, 'extracts', \"train.tsv\"), sep='\\t', index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WGkG5gbTCNss",
        "colab_type": "text"
      },
      "source": [
        "### Layer1 : 分かち書き（Tokenize）\n",
        "- 今回は Sentence Piece を使ってみる。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-HQrafwLsF7u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cd  \"$REPOSITORY_ROOT_DIR\"\n",
        "\n",
        "from WikiIterator import wiki_sentences\n",
        "# データを用意する。学習用、検証用、テスト用にそれぞれ24k, 3k, 3k文。\n",
        "train_size = 24000\n",
        "valid_size = 3000\n",
        "test_size = 3000\n",
        "\n",
        "gen = wiki_sentences()\n",
        "for filename, size in zip(\n",
        "    ['sp/wiki_train.txt', 'sp/wiki_valid.txt', 'sp/wiki_test.txt'],\n",
        "    [train_size, valid_size, test_size]):\n",
        "    \n",
        "    i = 0\n",
        "    output = ''\n",
        "    for text in gen:\n",
        "        output += text + '\\n'\n",
        "        i += 1\n",
        "        if i >= size:\n",
        "            with open(filename,  'w', encoding='utf-8') as f:\n",
        "                f.write(output)\n",
        "            break"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uh8S4bHDsF7w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 下記コマンドを走らせてSentencePieceのモデルを用意しておく\n",
        "!spm_train --input=sp/wiki_train.txt --model_prefix=sp/sp --vocab_size=8000"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "znZdt0QFsF7z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 学習したSentencePieceモデルを読み込む\n",
        "import sentencepiece as spm\n",
        "sp = spm.SentencePieceProcessor()\n",
        "sp.Load('sp/sp.model')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T4oFUSqWsF71",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# コーパスの頭を覗き見てみる\n",
        "i = 0\n",
        "for text in wiki_sentences():\n",
        "    print(' '.join(sp.EncodeAsPieces(text)))\n",
        "    i += 1\n",
        "    if i >= 5: break"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZJk65f1usF73",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import glob\n",
        "import os\n",
        "import time\n",
        "import math\n",
        "\n",
        "use_gpu = torch.cuda.is_available()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8s93K3D5sF75",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# wakati_corpus.txtから一部データを読み込む\n",
        "class Corpus(object):\n",
        "    def __init__(self):\n",
        "        self.sp = spm.SentencePieceProcessor()\n",
        "        self.sp.Load('sp/sp.model')\n",
        "\n",
        "        self.train = self.load_from_file('sp/wiki_train.txt')\n",
        "        self.valid = self.load_from_file('sp/wiki_valid.txt')\n",
        "        self.test = self.load_from_file('sp/wiki_test.txt')\n",
        "\n",
        "        self.train = self.assign_ids(self.train)\n",
        "        self.valid = self.assign_ids(self.valid)\n",
        "        self.test = self.assign_ids(self.test)\n",
        "    \n",
        "    def load_from_file(self, filename):\n",
        "        with open(filename, 'r', encoding='utf-8') as f:\n",
        "            return f.read().split('\\n')\n",
        "    \n",
        "    def assign_ids(self, texts):\n",
        "        tokens = []\n",
        "        for text in texts:\n",
        "            tokens.extend(self.sp.EncodeAsIds(text))\n",
        "        \n",
        "        ids = torch.from_numpy(np.array(tokens, dtype=np.int64))\n",
        "        return ids"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MQud0SV9S10U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# コーパスを実際に読み込む\n",
        "corpus = Corpus()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}